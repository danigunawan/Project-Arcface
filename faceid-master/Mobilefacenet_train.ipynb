{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T12:29:31.865871Z",
     "start_time": "2020-07-13T12:29:31.846870Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from PIL import Image, ImageFile\n",
    "from torch.nn import Parameter,Module, Sequential\n",
    "from torch.nn import Conv2d,BatchNorm2d, PReLU,Flatten,BatchNorm1d, Linear\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import math,os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T12:29:32.588873Z",
     "start_time": "2020-07-13T12:29:32.528874Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mobile Facenet\n",
    "def l2_norm(input, axis = 1):\n",
    "    norm = torch.norm(input, 2, axis, True)\n",
    "    output = torch.div(input, norm)\n",
    "    return output\n",
    "\n",
    "class Flatten(Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class Conv_block(Module):\n",
    "    def __init__(self, in_c, out_c, kernel = (1,1), stride = (1,1), padding = (0,0), groups = 1):\n",
    "        super(Conv_block, self).__init__()\n",
    "        self.conv = Conv2d(in_channels=in_c, \n",
    "                           out_channels = out_c, \n",
    "                           kernel_size = kernel,\n",
    "                           groups = groups,\n",
    "                           stride = stride,\n",
    "                           padding = padding,\n",
    "                           bias = False)\n",
    "        self.bn = BatchNorm2d(num_features =out_c)\n",
    "        self.prelu = PReLU(num_parameters = out_c)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.prelu(x)\n",
    "        return x\n",
    "    \n",
    "class Linear_block(Module):\n",
    "    def __init__(self, in_c, out_c, kernel=(1, 1), stride=(1, 1), padding=(0, 0), groups=1):\n",
    "        super(Linear_block, self).__init__()\n",
    "        self.conv = Conv2d(in_channels=in_c,\n",
    "                          out_channels= out_c,\n",
    "                          kernel_size = kernel,\n",
    "                          groups = groups,\n",
    "                          stride = stride,\n",
    "                          padding = padding,\n",
    "                          bias = False)\n",
    "        self.bn = BatchNorm2d(out_c)\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "    \n",
    "class Depth_Wise(Module):\n",
    "    def __init__(self, in_c, out_c, residual = False, kernel=(3, 3), stride=(2, 2), padding=(1, 1), groups=1):\n",
    "        super(Depth_Wise, self).__init__()\n",
    "        self.conv = Conv_block(in_c, out_c=groups, kernel=(1, 1), padding=(0, 0), stride=(1, 1))\n",
    "        self.conv_dw = Conv_block(groups, groups, groups=groups, kernel=kernel, padding=padding, stride=stride)\n",
    "        self.project = Linear_block(groups, out_c, kernel=(1, 1), padding=(0, 0), stride=(1, 1))\n",
    "        self.residual = residual\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.residual:\n",
    "            short_cut = x\n",
    "        x = self.conv(x)\n",
    "        x = self.conv_dw(x)\n",
    "        x = self.project(x)\n",
    "        if self.residual:\n",
    "            output = short_cut + x\n",
    "        else:\n",
    "            output = x\n",
    "        return output\n",
    "    \n",
    "class Residual(Module):\n",
    "    def __init__(self, c, num_block, groups, kernel = (3,3), stride = (1,1), padding = (1,1)):\n",
    "        super(Residual, self).__init__()\n",
    "        modules = []\n",
    "        for _ in range(num_block):\n",
    "            modules.append(Depth_Wise(c, c, residual = True, kernel = kernel, padding = padding, stride = stride, groups = groups ))\n",
    "        self.model = Sequential(*modules)\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "        \n",
    "class MobileFaceNet(Module):\n",
    "    def __init__(self, embedding_size):\n",
    "        super(MobileFaceNet, self).__init__()\n",
    "        self.conv1 = Conv_block(3, 64, kernel=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.conv2_dw = Conv_block(64, 64, kernel=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
    "        self.conv_23 = Depth_Wise(64, 64, kernel=(3, 3), stride=(2, 2), padding=(1, 1), groups=128)\n",
    "        self.conv_3 = Residual(64, num_block=4, groups=128, kernel=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.conv_34 = Depth_Wise(64, 128, kernel=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
    "        self.conv_4 = Residual(128, num_block=6, groups=256, kernel=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.conv_45 = Depth_Wise(128, 128, kernel=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)\n",
    "        self.conv_5 = Residual(128, num_block=2, groups=256, kernel=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.conv_6_sep = Conv_block(128, 512, kernel=(1, 1), stride=(1, 1), padding=(0, 0))\n",
    "        self.conv_6_dw = Linear_block(512, 512, groups=512, kernel=(7,7), stride=(1, 1), padding=(0, 0))\n",
    "        self.conv_6_flatten = Flatten()\n",
    "        self.linear = Linear(512, embedding_size, bias=False)\n",
    "        self.bn = BatchNorm1d(embedding_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2_dw(out)\n",
    "        out = self.conv_23(out)\n",
    "        out = self.conv_3(out)\n",
    "        out = self.conv_34(out)\n",
    "        out = self.conv_4(out)\n",
    "        out = self.conv_45(out)\n",
    "        out = self.conv_5(out)\n",
    "        out = self.conv_6_sep(out)\n",
    "        out = self.conv_6_dw(out)\n",
    "        out = self.conv_6_flatten(out)\n",
    "        out = self.linear(out)\n",
    "        out = self.bn(out)\n",
    "        return l2_norm(out)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T12:29:32.757874Z",
     "start_time": "2020-07-13T12:29:32.734873Z"
    }
   },
   "outputs": [],
   "source": [
    "# Arcface head\n",
    "class Arcface(Module):\n",
    "#     def __init__(self, embedding_size = 512, classnum = 51332, s = 64, m = 0.5):\n",
    "    def __init__(self, embedding_size = 512, classnum = 3, s = 64, m = 0.5):\n",
    "        super(Arcface, self).__init__()\n",
    "        self.classnum = classnum\n",
    "        self.kernel = Parameter(torch.Tensor(embedding_size, classnum))\n",
    "        \n",
    "        # initial kernel\n",
    "        self.kernel.data.uniform_(-1, 1).renorm_(2,1,1e-5).mul_(1e5)\n",
    "        self.m = m \n",
    "        self.s = s\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.mm = self.sin_m * m\n",
    "        self.threshold = math.cos(math.pi - m)\n",
    "        \n",
    "    def forward(self, embbedings, label):\n",
    "        # weights norm\n",
    "        nB = len(embbedings)\n",
    "        kernel_norm = l2_norm(self.kernel,axis=0)\n",
    "        # cos(theta+m)\n",
    "        cos_theta = torch.mm(embbedings,kernel_norm)  # inner_product\n",
    "#         output = torch.mm(embbedings,kernel_norm)\n",
    "        cos_theta = cos_theta.clamp(-1,1) # for numerical stability\n",
    "        cos_theta_2 = torch.pow(cos_theta, 2)\n",
    "        sin_theta_2 = 1 - cos_theta_2\n",
    "        sin_theta = torch.sqrt(sin_theta_2)\n",
    "        \n",
    "        # cos(theta + m)\n",
    "        cos_theta_m = (cos_theta * self.cos_m - sin_theta * self.sin_m)\n",
    "        \n",
    "        # this condition controls the theta+m should in range [0, pi]\n",
    "        #      0<=theta+m<=pi\n",
    "        #     -m<=theta<=pi-m\n",
    "        cond_v = cos_theta - self.threshold\n",
    "        cond_mask = cond_v <= 0\n",
    "        keep_val = (cos_theta - self.mm) # when theta not in [0,pi], use cosface instead\n",
    "        cos_theta_m[cond_mask] = keep_val[cond_mask]\n",
    "        output = cos_theta * 1.0 # a little bit hacky way to prevent in_place operation on cos_theta\n",
    "        idx_ = torch.arange(0, nB, dtype=torch.long)\n",
    "        output[idx_, label] = cos_theta_m[idx_, label]\n",
    "        output *= self.s # scale up in order to make softmax work, first introduced in normface\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T12:29:32.907873Z",
     "start_time": "2020-07-13T12:29:32.894874Z"
    }
   },
   "outputs": [],
   "source": [
    "class faceLoader:\n",
    "    def __init__(self, data_root, batch_size, shuffle = True):\n",
    "            self.data_root = data_root\n",
    "            self.batch_size = batch_size\n",
    "            self.shuffle = shuffle\n",
    "            \n",
    "    def get_loader(self, img_size = [112,112]):\n",
    "        train_transforms = transforms.Compose([\n",
    "            transforms.Resize(img_size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])\n",
    "        ])\n",
    "        \n",
    "        train_datasets = ImageFolder(self.data_root, train_transforms)\n",
    "        train_loader = DataLoader(train_datasets, batch_size = self.batch_size, num_workers = 4, pin_memory = True)\n",
    "        \n",
    "        num_classes = train_datasets[-1][1] + 1\n",
    "        \n",
    "        return train_loader, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T14:31:14.728883Z",
     "start_time": "2020-07-13T14:31:14.701872Z"
    }
   },
   "outputs": [],
   "source": [
    "class faceTrainer:\n",
    "    def __init__(self, device, dataloader, embedding_size= 512):\n",
    "        print('Trainer Initializing')\n",
    "        \n",
    "        self.step = 0\n",
    "        self.device = device\n",
    "        self.model = MobileFaceNet(embedding_size)\n",
    "        print(summary(self.model, (3,112,112)))\n",
    "        \n",
    "        if torch.cuda.device_count() >1:\n",
    "            print('CUDAs', torch.cuda.device_count(), 'GPUs')\n",
    "        self.model = self.model.to(self.device)\n",
    "        \n",
    "        self.train_loader, self.class_num = dataloader.get_loader()\n",
    "        \n",
    "        self.header = Arcface(embedding_size = embedding_size, classnum = self.class_num).to(self.device)\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr = 1e-1, weight_decay = 5e-4)\n",
    "        self.scheduler = StepLR(self.optimizer, step_size = 10, gamma = 0.1)\n",
    "        self.loss = CrossEntropyLoss()\n",
    "        \n",
    "    def train(self, epochs, print_freq):\n",
    "        self.model.train()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            self.step = 0\n",
    "            train_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for imgs, labels in iter(self.train_loader):\n",
    "                \n",
    "                imgs = imgs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                # Gradient Initialization\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                embeddings = self.model(imgs)\n",
    "                thetas = self.header(embeddings, labels)\n",
    "                output = self.loss(thetas, labels)\n",
    "                output.backward()\n",
    "                train_loss += output.item()\n",
    "                \n",
    "                self.optimizer.step()\n",
    "                \n",
    "                if self.step % print_freq == 0 and self.step !=0:\n",
    "                    print('epoch:', epoch, 'step:', self.step, 'loss', output.item())\n",
    "                    \n",
    "                self.step +=1\n",
    "                \n",
    "            loss_avg = train_loss/len(self.train_loader)\n",
    "            if not os.path.isdir('./data/weights_lr'):\n",
    "                os.makedirs('./data/weights_lr')\n",
    "            \n",
    "            torch.save(self.header.state_dict(), f'./data/weights_lr/{str(epoch)}_{str(loss_avg)}.pth')\n",
    "            print('epoch:', epoch, 'loss_avg', loss_avg)\n",
    "\n",
    "            self.scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T14:31:22.723941Z",
     "start_time": "2020-07-13T14:31:22.717935Z"
    }
   },
   "outputs": [],
   "source": [
    "def start():\n",
    "    print('Strated')\n",
    "    data_root = './db/small_vgg/train'\n",
    "#     batch_size = 64\n",
    "    batch_size = 8\n",
    "\n",
    "    classnum = 3\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    print('data Loading')\n",
    "    dataloader = faceLoader(data_root, batch_size, shuffle = True)\n",
    "    trainer = faceTrainer(device, dataloader, embedding_size = 512)\n",
    "    print('Begin Trianing on:', device)\n",
    "    trainer.train(50, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T23:02:40.334485Z",
     "start_time": "2020-07-13T14:31:22.964939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strated\n",
      "data Loading\n",
      "Trainer Initializing\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 56, 56]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 56, 56]             128\n",
      "             PReLU-3           [-1, 64, 56, 56]              64\n",
      "        Conv_block-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]             576\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "             PReLU-7           [-1, 64, 56, 56]              64\n",
      "        Conv_block-8           [-1, 64, 56, 56]               0\n",
      "            Conv2d-9          [-1, 128, 56, 56]           8,192\n",
      "      BatchNorm2d-10          [-1, 128, 56, 56]             256\n",
      "            PReLU-11          [-1, 128, 56, 56]             128\n",
      "       Conv_block-12          [-1, 128, 56, 56]               0\n",
      "           Conv2d-13          [-1, 128, 28, 28]           1,152\n",
      "      BatchNorm2d-14          [-1, 128, 28, 28]             256\n",
      "            PReLU-15          [-1, 128, 28, 28]             128\n",
      "       Conv_block-16          [-1, 128, 28, 28]               0\n",
      "           Conv2d-17           [-1, 64, 28, 28]           8,192\n",
      "      BatchNorm2d-18           [-1, 64, 28, 28]             128\n",
      "     Linear_block-19           [-1, 64, 28, 28]               0\n",
      "       Depth_Wise-20           [-1, 64, 28, 28]               0\n",
      "           Conv2d-21          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-22          [-1, 128, 28, 28]             256\n",
      "            PReLU-23          [-1, 128, 28, 28]             128\n",
      "       Conv_block-24          [-1, 128, 28, 28]               0\n",
      "           Conv2d-25          [-1, 128, 28, 28]           1,152\n",
      "      BatchNorm2d-26          [-1, 128, 28, 28]             256\n",
      "            PReLU-27          [-1, 128, 28, 28]             128\n",
      "       Conv_block-28          [-1, 128, 28, 28]               0\n",
      "           Conv2d-29           [-1, 64, 28, 28]           8,192\n",
      "      BatchNorm2d-30           [-1, 64, 28, 28]             128\n",
      "     Linear_block-31           [-1, 64, 28, 28]               0\n",
      "       Depth_Wise-32           [-1, 64, 28, 28]               0\n",
      "           Conv2d-33          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-34          [-1, 128, 28, 28]             256\n",
      "            PReLU-35          [-1, 128, 28, 28]             128\n",
      "       Conv_block-36          [-1, 128, 28, 28]               0\n",
      "           Conv2d-37          [-1, 128, 28, 28]           1,152\n",
      "      BatchNorm2d-38          [-1, 128, 28, 28]             256\n",
      "            PReLU-39          [-1, 128, 28, 28]             128\n",
      "       Conv_block-40          [-1, 128, 28, 28]               0\n",
      "           Conv2d-41           [-1, 64, 28, 28]           8,192\n",
      "      BatchNorm2d-42           [-1, 64, 28, 28]             128\n",
      "     Linear_block-43           [-1, 64, 28, 28]               0\n",
      "       Depth_Wise-44           [-1, 64, 28, 28]               0\n",
      "           Conv2d-45          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-46          [-1, 128, 28, 28]             256\n",
      "            PReLU-47          [-1, 128, 28, 28]             128\n",
      "       Conv_block-48          [-1, 128, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]           1,152\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "            PReLU-51          [-1, 128, 28, 28]             128\n",
      "       Conv_block-52          [-1, 128, 28, 28]               0\n",
      "           Conv2d-53           [-1, 64, 28, 28]           8,192\n",
      "      BatchNorm2d-54           [-1, 64, 28, 28]             128\n",
      "     Linear_block-55           [-1, 64, 28, 28]               0\n",
      "       Depth_Wise-56           [-1, 64, 28, 28]               0\n",
      "           Conv2d-57          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-58          [-1, 128, 28, 28]             256\n",
      "            PReLU-59          [-1, 128, 28, 28]             128\n",
      "       Conv_block-60          [-1, 128, 28, 28]               0\n",
      "           Conv2d-61          [-1, 128, 28, 28]           1,152\n",
      "      BatchNorm2d-62          [-1, 128, 28, 28]             256\n",
      "            PReLU-63          [-1, 128, 28, 28]             128\n",
      "       Conv_block-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65           [-1, 64, 28, 28]           8,192\n",
      "      BatchNorm2d-66           [-1, 64, 28, 28]             128\n",
      "     Linear_block-67           [-1, 64, 28, 28]               0\n",
      "       Depth_Wise-68           [-1, 64, 28, 28]               0\n",
      "         Residual-69           [-1, 64, 28, 28]               0\n",
      "           Conv2d-70          [-1, 256, 28, 28]          16,384\n",
      "      BatchNorm2d-71          [-1, 256, 28, 28]             512\n",
      "            PReLU-72          [-1, 256, 28, 28]             256\n",
      "       Conv_block-73          [-1, 256, 28, 28]               0\n",
      "           Conv2d-74          [-1, 256, 14, 14]           2,304\n",
      "      BatchNorm2d-75          [-1, 256, 14, 14]             512\n",
      "            PReLU-76          [-1, 256, 14, 14]             256\n",
      "       Conv_block-77          [-1, 256, 14, 14]               0\n",
      "           Conv2d-78          [-1, 128, 14, 14]          32,768\n",
      "      BatchNorm2d-79          [-1, 128, 14, 14]             256\n",
      "     Linear_block-80          [-1, 128, 14, 14]               0\n",
      "       Depth_Wise-81          [-1, 128, 14, 14]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "            PReLU-84          [-1, 256, 14, 14]             256\n",
      "       Conv_block-85          [-1, 256, 14, 14]               0\n",
      "           Conv2d-86          [-1, 256, 14, 14]           2,304\n",
      "      BatchNorm2d-87          [-1, 256, 14, 14]             512\n",
      "            PReLU-88          [-1, 256, 14, 14]             256\n",
      "       Conv_block-89          [-1, 256, 14, 14]               0\n",
      "           Conv2d-90          [-1, 128, 14, 14]          32,768\n",
      "      BatchNorm2d-91          [-1, 128, 14, 14]             256\n",
      "     Linear_block-92          [-1, 128, 14, 14]               0\n",
      "       Depth_Wise-93          [-1, 128, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "            PReLU-96          [-1, 256, 14, 14]             256\n",
      "       Conv_block-97          [-1, 256, 14, 14]               0\n",
      "           Conv2d-98          [-1, 256, 14, 14]           2,304\n",
      "      BatchNorm2d-99          [-1, 256, 14, 14]             512\n",
      "           PReLU-100          [-1, 256, 14, 14]             256\n",
      "      Conv_block-101          [-1, 256, 14, 14]               0\n",
      "          Conv2d-102          [-1, 128, 14, 14]          32,768\n",
      "     BatchNorm2d-103          [-1, 128, 14, 14]             256\n",
      "    Linear_block-104          [-1, 128, 14, 14]               0\n",
      "      Depth_Wise-105          [-1, 128, 14, 14]               0\n",
      "          Conv2d-106          [-1, 256, 14, 14]          32,768\n",
      "     BatchNorm2d-107          [-1, 256, 14, 14]             512\n",
      "           PReLU-108          [-1, 256, 14, 14]             256\n",
      "      Conv_block-109          [-1, 256, 14, 14]               0\n",
      "          Conv2d-110          [-1, 256, 14, 14]           2,304\n",
      "     BatchNorm2d-111          [-1, 256, 14, 14]             512\n",
      "           PReLU-112          [-1, 256, 14, 14]             256\n",
      "      Conv_block-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 128, 14, 14]          32,768\n",
      "     BatchNorm2d-115          [-1, 128, 14, 14]             256\n",
      "    Linear_block-116          [-1, 128, 14, 14]               0\n",
      "      Depth_Wise-117          [-1, 128, 14, 14]               0\n",
      "          Conv2d-118          [-1, 256, 14, 14]          32,768\n",
      "     BatchNorm2d-119          [-1, 256, 14, 14]             512\n",
      "           PReLU-120          [-1, 256, 14, 14]             256\n",
      "      Conv_block-121          [-1, 256, 14, 14]               0\n",
      "          Conv2d-122          [-1, 256, 14, 14]           2,304\n",
      "     BatchNorm2d-123          [-1, 256, 14, 14]             512\n",
      "           PReLU-124          [-1, 256, 14, 14]             256\n",
      "      Conv_block-125          [-1, 256, 14, 14]               0\n",
      "          Conv2d-126          [-1, 128, 14, 14]          32,768\n",
      "     BatchNorm2d-127          [-1, 128, 14, 14]             256\n",
      "    Linear_block-128          [-1, 128, 14, 14]               0\n",
      "      Depth_Wise-129          [-1, 128, 14, 14]               0\n",
      "          Conv2d-130          [-1, 256, 14, 14]          32,768\n",
      "     BatchNorm2d-131          [-1, 256, 14, 14]             512\n",
      "           PReLU-132          [-1, 256, 14, 14]             256\n",
      "      Conv_block-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]           2,304\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "           PReLU-136          [-1, 256, 14, 14]             256\n",
      "      Conv_block-137          [-1, 256, 14, 14]               0\n",
      "          Conv2d-138          [-1, 128, 14, 14]          32,768\n",
      "     BatchNorm2d-139          [-1, 128, 14, 14]             256\n",
      "    Linear_block-140          [-1, 128, 14, 14]               0\n",
      "      Depth_Wise-141          [-1, 128, 14, 14]               0\n",
      "          Conv2d-142          [-1, 256, 14, 14]          32,768\n",
      "     BatchNorm2d-143          [-1, 256, 14, 14]             512\n",
      "           PReLU-144          [-1, 256, 14, 14]             256\n",
      "      Conv_block-145          [-1, 256, 14, 14]               0\n",
      "          Conv2d-146          [-1, 256, 14, 14]           2,304\n",
      "     BatchNorm2d-147          [-1, 256, 14, 14]             512\n",
      "           PReLU-148          [-1, 256, 14, 14]             256\n",
      "      Conv_block-149          [-1, 256, 14, 14]               0\n",
      "          Conv2d-150          [-1, 128, 14, 14]          32,768\n",
      "     BatchNorm2d-151          [-1, 128, 14, 14]             256\n",
      "    Linear_block-152          [-1, 128, 14, 14]               0\n",
      "      Depth_Wise-153          [-1, 128, 14, 14]               0\n",
      "        Residual-154          [-1, 128, 14, 14]               0\n",
      "          Conv2d-155          [-1, 512, 14, 14]          65,536\n",
      "     BatchNorm2d-156          [-1, 512, 14, 14]           1,024\n",
      "           PReLU-157          [-1, 512, 14, 14]             512\n",
      "      Conv_block-158          [-1, 512, 14, 14]               0\n",
      "          Conv2d-159            [-1, 512, 7, 7]           4,608\n",
      "     BatchNorm2d-160            [-1, 512, 7, 7]           1,024\n",
      "           PReLU-161            [-1, 512, 7, 7]             512\n",
      "      Conv_block-162            [-1, 512, 7, 7]               0\n",
      "          Conv2d-163            [-1, 128, 7, 7]          65,536\n",
      "     BatchNorm2d-164            [-1, 128, 7, 7]             256\n",
      "    Linear_block-165            [-1, 128, 7, 7]               0\n",
      "      Depth_Wise-166            [-1, 128, 7, 7]               0\n",
      "          Conv2d-167            [-1, 256, 7, 7]          32,768\n",
      "     BatchNorm2d-168            [-1, 256, 7, 7]             512\n",
      "           PReLU-169            [-1, 256, 7, 7]             256\n",
      "      Conv_block-170            [-1, 256, 7, 7]               0\n",
      "          Conv2d-171            [-1, 256, 7, 7]           2,304\n",
      "     BatchNorm2d-172            [-1, 256, 7, 7]             512\n",
      "           PReLU-173            [-1, 256, 7, 7]             256\n",
      "      Conv_block-174            [-1, 256, 7, 7]               0\n",
      "          Conv2d-175            [-1, 128, 7, 7]          32,768\n",
      "     BatchNorm2d-176            [-1, 128, 7, 7]             256\n",
      "    Linear_block-177            [-1, 128, 7, 7]               0\n",
      "      Depth_Wise-178            [-1, 128, 7, 7]               0\n",
      "          Conv2d-179            [-1, 256, 7, 7]          32,768\n",
      "     BatchNorm2d-180            [-1, 256, 7, 7]             512\n",
      "           PReLU-181            [-1, 256, 7, 7]             256\n",
      "      Conv_block-182            [-1, 256, 7, 7]               0\n",
      "          Conv2d-183            [-1, 256, 7, 7]           2,304\n",
      "     BatchNorm2d-184            [-1, 256, 7, 7]             512\n",
      "           PReLU-185            [-1, 256, 7, 7]             256\n",
      "      Conv_block-186            [-1, 256, 7, 7]               0\n",
      "          Conv2d-187            [-1, 128, 7, 7]          32,768\n",
      "     BatchNorm2d-188            [-1, 128, 7, 7]             256\n",
      "    Linear_block-189            [-1, 128, 7, 7]               0\n",
      "      Depth_Wise-190            [-1, 128, 7, 7]               0\n",
      "        Residual-191            [-1, 128, 7, 7]               0\n",
      "          Conv2d-192            [-1, 512, 7, 7]          65,536\n",
      "     BatchNorm2d-193            [-1, 512, 7, 7]           1,024\n",
      "           PReLU-194            [-1, 512, 7, 7]             512\n",
      "      Conv_block-195            [-1, 512, 7, 7]               0\n",
      "          Conv2d-196            [-1, 512, 1, 1]          25,088\n",
      "     BatchNorm2d-197            [-1, 512, 1, 1]           1,024\n",
      "    Linear_block-198            [-1, 512, 1, 1]               0\n",
      "         Flatten-199                  [-1, 512]               0\n",
      "          Linear-200                  [-1, 512]         262,144\n",
      "     BatchNorm1d-201                  [-1, 512]           1,024\n",
      "================================================================\n",
      "Total params: 1,200,512\n",
      "Trainable params: 1,200,512\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.14\n",
      "Forward/backward pass size (MB): 98.45\n",
      "Params size (MB): 4.58\n",
      "Estimated Total Size (MB): 103.18\n",
      "----------------------------------------------------------------\n",
      "None\n",
      "Begin Trianing on: cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 step: 100 loss 15.133891105651855\n",
      "epoch: 0 loss_avg 20.697264048058216\n",
      "epoch: 1 step: 100 loss 9.070046424865723\n",
      "epoch: 1 loss_avg 17.075614635399948\n",
      "epoch: 2 step: 100 loss 3.2182557582855225\n",
      "epoch: 2 loss_avg 18.00717204762256\n",
      "epoch: 3 step: 100 loss 2.502995014190674\n",
      "epoch: 3 loss_avg 15.694953623719103\n",
      "epoch: 4 step: 100 loss 4.19165563583374\n",
      "epoch: 4 loss_avg 15.482749274396522\n",
      "epoch: 5 step: 100 loss 5.9325032234191895\n",
      "epoch: 5 loss_avg 18.871565285630112\n",
      "epoch: 6 step: 100 loss 3.4222664833068848\n",
      "epoch: 6 loss_avg 12.876978333540789\n",
      "epoch: 7 step: 100 loss 4.630937099456787\n",
      "epoch: 7 loss_avg 14.121239853656197\n",
      "epoch: 8 step: 100 loss 2.8835349082946777\n",
      "epoch: 8 loss_avg 11.823997749118355\n",
      "epoch: 9 step: 100 loss 2.6124894618988037\n",
      "epoch: 9 loss_avg 12.173814538895614\n",
      "epoch: 10 step: 100 loss 9.021117210388184\n",
      "epoch: 10 loss_avg 26.493115719847793\n",
      "epoch: 11 step: 100 loss 12.610273361206055\n",
      "epoch: 11 loss_avg 25.287000832595226\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-85ba4973bfbb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-49-4ad4c0af4f60>\u001b[0m in \u001b[0;36mstart\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mtrainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfaceTrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Begin Trianing on:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-47-6fcc90839a22>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, epochs, print_freq)\u001b[0m\n\u001b[0;32m     39\u001b[0m                 \u001b[0mthetas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthetas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m                 \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m                 \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shiney\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
